{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a571685b-6479-487f-90f0-f9ee0a756143",
   "metadata": {},
   "source": [
    "# For Sample\n",
    "[Convolutional Network Visualizations & Deep Dream](https://www.kaggle.com/code/carloalbertobarbano/convolutional-network-visualizations-deep-dream/notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e80ea86d-2246-460c-9a18-6629d69b2292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import SGD\n",
    "from torchvision import models, transforms\n",
    "import PIL\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import scipy.ndimage as ndimage\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.ndimage as nd\n",
    "import PIL.Image\n",
    "from IPython.display import clear_output, Image, display\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12fad6b-22bf-4a3a-8908-137a69110d81",
   "metadata": {},
   "source": [
    "# np.uint8(np.clip(image, 0, 255))\n",
    "* 0 ~ 255 の値に収め、uint8のnp型にキャストする\n",
    "\n",
    "# バイト列を格納するBufferを用意する\n",
    "* buffer = BytesIO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e8b0d4c-9b3d-443d-871d-c8eaf371cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_array(image, format='jpg'):\n",
    "    clip_np_image = np.uint8(np.clip(image, 0, 255))\n",
    "    buffer = BytesIO()\n",
    "    \n",
    "    PIL.Image.fromarray(clip_np_image).save(buffer, format)\n",
    "    display(Image(data=buffer.getvalue()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee11692e-1dad-4c13-926b-76629067ffa5",
   "metadata": {},
   "source": [
    "# reshapeは配列を形状変換する\n",
    "* mean(平均)\n",
    "    * [0.485 0.456 0.406] -> [[[0.485 0.456 0.406]]]\n",
    "* std(標準偏差)\n",
    "    * [0.229, 0.224, 0.225] -> [[[0.229, 0.224, 0.225]]]\n",
    "* inp(インプット)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "922b2d09-2e19-44ce-b99b-aa87a523d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor(image):\n",
    "    maen = np.array([0.485, 0.456, 0.406]).reshape([1, 1, 3])\n",
    "    std = np.array([0.229, 0.224, 0.225]).reshape([1, 1, 3])\n",
    "\n",
    "    # インプット\n",
    "    inp = a[0, :, :, :]\n",
    "    inp = inp.transpose(1, 2, 0)\n",
    "    inp = std * inp + mean\n",
    "    inp *= 255\n",
    "\n",
    "    showarray(inp)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcafe9f7-6d30-400d-8642-8ae834d58049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_imaages(image, title=None):\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(10 / 5 + 1, 5, i + 1)\n",
    "        plt.axis('off')\n",
    "        if titles is not None:\n",
    "            plt.title(titles[i])\n",
    "        plt.imshow(images[i])\n",
    "        \n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d11f3f4-909c-47e0-bf87-2496e8f8ac26",
   "metadata": {},
   "source": [
    "# ToTensor\n",
    "* PIL Image をテンソルに変換する Transform\n",
    "* 値の範囲は [0, 1] の float にスケールされる\n",
    "* 形状は (C, H, W) になる\n",
    "# Normalize\n",
    "* 正規化を行う Transform \n",
    "* n 個のチャンネルごとの平均 (m1,m2,⋯ ,mn),及び標準偏差 (s1,s2,⋯ ,sn) が与えられたとき、チャンネルごとに次のように標準化を行います。\n",
    "$$ \n",
    "    output_c = \\frac{input_c – m_c}s_c\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e22473f8-e04a-47a1-85a6-49ae86b178b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalise = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "normalise_resize = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
