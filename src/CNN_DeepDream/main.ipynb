{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a571685b-6479-487f-90f0-f9ee0a756143",
   "metadata": {},
   "source": [
    "# For Sample\n",
    "[Convolutional Network Visualizations & Deep Dream](https://www.kaggle.com/code/carloalbertobarbano/convolutional-network-visualizations-deep-dream/notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e80ea86d-2246-460c-9a18-6629d69b2292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import SGD\n",
    "from torchvision import models, transforms\n",
    "import PIL\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import scipy.ndimage as ndimage\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.ndimage as nd\n",
    "import PIL.Image\n",
    "from IPython.display import clear_output, Image, display\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad6209e4-1ce9-4202-9faa-d75c82fba5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN_DEFINE = [0.485, 0.456, 0.406]\n",
    "STD_DEFINE = [0.229, 0.224, 0.225]\n",
    "IMAGE_RESIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12fad6b-22bf-4a3a-8908-137a69110d81",
   "metadata": {},
   "source": [
    "# np.uint8(np.clip(image, 0, 255))\n",
    "* 0 ~ 255 の値に収め、uint8のnp型にキャストする\n",
    "\n",
    "# バイト列を格納するBufferを用意する\n",
    "* buffer = BytesIO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e8b0d4c-9b3d-443d-871d-c8eaf371cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_array(image, format='jpg'):\n",
    "    clip_np_image = np.uint8(np.clip(image, 0, 255))\n",
    "    buffer = BytesIO()\n",
    "    \n",
    "    PIL.Image.fromarray(clip_np_image).save(buffer, format)\n",
    "    display(Image(data=buffer.getvalue()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee11692e-1dad-4c13-926b-76629067ffa5",
   "metadata": {},
   "source": [
    "# reshapeは配列を形状変換する\n",
    "* mean(平均)\n",
    "    * [0.485 0.456 0.406] -> [[[0.485 0.456 0.406]]]\n",
    "* std(標準偏差)\n",
    "    * [0.229, 0.224, 0.225] -> [[[0.229, 0.224, 0.225]]]\n",
    "* inp(インプット)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "922b2d09-2e19-44ce-b99b-aa87a523d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor(image):\n",
    "    maen = np.array(MEAN_DEFINE).reshape([1, 1, 3])\n",
    "    std = np.array(STD_DEFINE).reshape([1, 1, 3])\n",
    "\n",
    "    # インプット\n",
    "    inp = image[0, :, :, :]\n",
    "    inp = inp.transpose(1, 2, 0)\n",
    "    inp = std * inp + mean\n",
    "    inp *= 255\n",
    "\n",
    "    showarray(inp)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcafe9f7-6d30-400d-8642-8ae834d58049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_imaages(image, title=None):\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(10 / 5 + 1, 5, i + 1)\n",
    "        plt.axis('off')\n",
    "        if titles is not None:\n",
    "            plt.title(titles[i])\n",
    "        plt.imshow(images[i])\n",
    "        \n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d11f3f4-909c-47e0-bf87-2496e8f8ac26",
   "metadata": {},
   "source": [
    "# Resize\n",
    "* リサイズを行うTransform\n",
    "# ToTensor\n",
    "* PIL Image をテンソルに変換する Transform\n",
    "* 値の範囲は [0, 1] の float にスケールされる\n",
    "* 形状は (C, H, W) になる\n",
    "# Normalize\n",
    "* 正規化を行う Transform \n",
    "* n 個のチャンネルごとの平均 (m1,m2,⋯ ,mn),及び標準偏差 (s1,s2,⋯ ,sn) が与えられたとき、チャンネルごとに次のように標準化を行います。\n",
    "$$ \n",
    "    output_c = \\frac{input_c – m_c}s_c\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e22473f8-e04a-47a1-85a6-49ae86b178b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalise = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN_DEFINE, STD_DEFINE)\n",
    "])\n",
    "\n",
    "normalise_resize = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_RESIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN_DEFINE, STD_DEFINE)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903a020d-e4db-4de1-8dcb-c62b22b7c8f5",
   "metadata": {},
   "source": [
    "# np.full\n",
    "* 任意の値で全要素を初期化したndarrayを生成する\n",
    "* np.full(n, m, z) # n行 * m列 z次元\n",
    "\n",
    "# numpy.random.uniform(low, high, size)\n",
    "* 任意の範囲の連続一様分布から浮動小数点数の乱数を生成する\n",
    "\n",
    "# torch.unsqueeze\n",
    "* 指定した位置にサイズ1の次元を挿入する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1604a962-e990-4e5a-a65e-a2c7fb486ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_image(size=(400, 400, 3)):\n",
    "    initalize_image = PIL.Image.fromarray(np.uint8(np.full(size, 150)))\n",
    "    random_create_image = PIL.Image.fromarray(np.uint8(np.random.uniform(150, 180, size)))\n",
    "    image_tensor = normalise(random_create_image).unsqueeze(0)\n",
    "    image_np = img_tensor.numpy()\n",
    "    return random_create_image, image_tensor, image_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcb57cf-4b3d-4803-b862-39b933125bc8",
   "metadata": {},
   "source": [
    "# PIL.Image.ANTIALIAS\n",
    "* アンチエイリアスで写真をキレイに縮小\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "754e561c-553d-4e76-bb26-0910f5f5be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_path(path, resize=False, size=None):\n",
    "    image = PIL.Image.open(path)\n",
    "    \n",
    "    if size is not None:\n",
    "        image.thumbnailmb(size, PIL.Image.ANTIALIAS)\n",
    "        \n",
    "    if resize:\n",
    "        image_tensor = normalise_resize(image).unsqueeze(0)\n",
    "    else:\n",
    "        image_tensor = normalise(image).unsquee(0)\n",
    "    image_np = image_tensor.numpy()\n",
    "    \n",
    "    return image, image_tensor, image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60cd3a6e-476a-4230-8b87-e21cb502a724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_image(tensor):\n",
    "    to_np = tensor.numpy()\n",
    "    mean = np.array(MEAN_DEFINE).reshape([1, 1, 3])\n",
    "    std = np.array(STD_DEFINE).reshape([1, 1, 3])\n",
    "    inp = to_np[0, :, :, :]\n",
    "    inp = inp.transpose(1, 2, 0)\n",
    "    inp = std * inp + mean\n",
    "    inp *= 255\n",
    "    inp = np.uint8(np.clip(inp, 0, 255))\n",
    "    return PIL.Image.fromarray(inp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
